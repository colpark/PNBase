{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Sinusoidal Neural Field Interpolation Evaluation\n",
    "\n",
    "This notebook evaluates PixNerd's neural field interpolation capabilities.\n",
    "\n",
    "## Benchmark Design\n",
    "\n",
    "- **Training**: Model trained on only 20% of pixels (regular stripe intervals)\n",
    "- **Testing**: Evaluate reconstruction quality on the unseen 80%\n",
    "- **Ground Truth**: Known sinusoidal patterns (smooth, continuous)\n",
    "\n",
    "### Visibility Pattern (Default)\n",
    "- Visible columns: [0%, 5%], [30%, 35%], [50%, 55%], [70%, 75%]\n",
    "- Total visible: 20%\n",
    "- Unseen: 80%\n",
    "\n",
    "### Key Metrics\n",
    "1. **Visible MSE**: Error on training regions (should be low)\n",
    "2. **Invisible MSE**: Error on unseen regions (interpolation quality)\n",
    "3. **Interpolation Ratio**: invisible_mse / visible_mse (lower = better interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PIXNERD_DIR = NOTEBOOK_DIR / \"PixNerd\"\n",
    "\n",
    "if PIXNERD_DIR.exists():\n",
    "    os.chdir(PIXNERD_DIR)\n",
    "    sys.path.insert(0, str(PIXNERD_DIR))\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"ERROR: PixNerd directory not found at {PIXNERD_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Must match training!\n",
    "# =============================================================================\n",
    "\n",
    "CHECKPOINT_PATH = str(NOTEBOOK_DIR / \"workdirs/exp_sinusoidal_nf_test/checkpoints/last.ckpt\")\n",
    "\n",
    "# Dataset config\n",
    "RESOLUTION = 64\n",
    "CHANNELS = 1\n",
    "NUM_COMPONENTS = 5\n",
    "\n",
    "# Model config\n",
    "PATCH_SIZE = 4\n",
    "HIDDEN_SIZE = 256\n",
    "DECODER_HIDDEN_SIZE = 64\n",
    "NUM_ENCODER_BLOCKS = 6\n",
    "NUM_DECODER_BLOCKS = 2\n",
    "NUM_GROUPS = 4\n",
    "\n",
    "# Visibility config (must match training)\n",
    "VISIBLE_INTERVALS = [\n",
    "    (0.0, 0.05),\n",
    "    (0.30, 0.35),\n",
    "    (0.50, 0.55),\n",
    "    (0.70, 0.75),\n",
    "]\n",
    "MASK_MODE = \"columns\"\n",
    "\n",
    "# Sampling\n",
    "NUM_SAMPLE_STEPS = 50\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"Resolution: {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"Visible intervals: {VISIBLE_INTERVALS}\")\n",
    "print(f\"Total visible: {sum(e-s for s,e in VISIBLE_INTERVALS):.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.autoencoder.pixel import PixelAE\n",
    "from src.models.transformer.pixnerd_c2i_heavydecoder import PixNerDiT\n",
    "from src.diffusion.flow_matching.scheduling import LinearScheduler\n",
    "from src.diffusion.flow_matching.sampling import EulerSampler, ode_step_fn\n",
    "from src.diffusion.base.guidance import simple_guidance_fn\n",
    "\n",
    "# Import dataset utilities\n",
    "sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "from train_sinusoidal import SinusoidalPLModule, SinusoidalLightningModel, SimpleEMA\n",
    "from train_sinusoidal import UnconditionalConditioner, MaskedFlowMatchingTrainer\n",
    "from PixNerd.src.data.dataset.sinusoidal import (\n",
    "    generate_sinusoidal_image,\n",
    "    create_visibility_mask,\n",
    "    compute_interpolation_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    scheduler = LinearScheduler()\n",
    "    vae = PixelAE(scale=1.0)\n",
    "    conditioner = UnconditionalConditioner()\n",
    "    \n",
    "    denoiser = PixNerDiT(\n",
    "        in_channels=CHANNELS,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        num_groups=NUM_GROUPS,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        decoder_hidden_size=DECODER_HIDDEN_SIZE,\n",
    "        num_encoder_blocks=NUM_ENCODER_BLOCKS,\n",
    "        num_decoder_blocks=NUM_DECODER_BLOCKS,\n",
    "        num_classes=1,\n",
    "    )\n",
    "    \n",
    "    trainer = MaskedFlowMatchingTrainer(\n",
    "        scheduler=scheduler,\n",
    "        lognorm_t=True,\n",
    "        timeshift=1.0,\n",
    "    )\n",
    "    \n",
    "    sampler = EulerSampler(\n",
    "        num_steps=NUM_SAMPLE_STEPS,\n",
    "        guidance=1.0,\n",
    "        guidance_interval_min=0.0,\n",
    "        guidance_interval_max=1.0,\n",
    "        scheduler=scheduler,\n",
    "        w_scheduler=LinearScheduler(),\n",
    "        guidance_fn=simple_guidance_fn,\n",
    "        step_fn=ode_step_fn,\n",
    "    )\n",
    "    \n",
    "    ema_tracker = SimpleEMA(decay=0.9999)\n",
    "    \n",
    "    model = SinusoidalLightningModel(\n",
    "        vae=vae,\n",
    "        conditioner=conditioner,\n",
    "        denoiser=denoiser,\n",
    "        diffusion_trainer=trainer,\n",
    "        diffusion_sampler=sampler,\n",
    "        ema_tracker=ema_tracker,\n",
    "        optimizer=None,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model.setup_ema()\n",
    "\n",
    "print(f\"\\nLoading checkpoint: {CHECKPOINT_PATH}\")\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    # Extract model state from Lightning checkpoint\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    # Remove 'model.' prefix if present\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('model.'):\n",
    "            new_state_dict[k[6:]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    print(\"Checkpoint loaded!\")\n",
    "else:\n",
    "    print(f\"WARNING: Checkpoint not found!\")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.denoiser.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Create Visibility Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visibility mask\n",
    "visibility_mask = create_visibility_mask(\n",
    "    RESOLUTION, VISIBLE_INTERVALS, MASK_MODE\n",
    ")\n",
    "\n",
    "visible_ratio = visibility_mask.sum() / visibility_mask.size\n",
    "\n",
    "print(f\"Visibility mask shape: {visibility_mask.shape}\")\n",
    "print(f\"Visible pixels: {visibility_mask.sum()} / {visibility_mask.size} ({visible_ratio:.1%})\")\n",
    "\n",
    "# Visualize mask\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(visibility_mask, cmap='RdYlGn', interpolation='nearest')\n",
    "plt.title(f\"Visibility Mask ({visible_ratio:.0%} visible = green)\")\n",
    "plt.colorbar(label=\"Visible\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Generate Ground Truth Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_samples(num_samples=10, seed_start=1000):\n",
    "    \"\"\"Generate ground truth sinusoidal images for testing.\"\"\"\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        img = generate_sinusoidal_image(\n",
    "            RESOLUTION, NUM_COMPONENTS,\n",
    "            freq_range=(1.0, 8.0),\n",
    "            seed=seed_start + i\n",
    "        )\n",
    "        samples.append(img)\n",
    "    return np.stack(samples)\n",
    "\n",
    "\n",
    "# Generate test samples\n",
    "test_samples = generate_test_samples(10)\n",
    "print(f\"Generated {len(test_samples)} test samples\")\n",
    "\n",
    "# Display a few\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, (ax, img) in enumerate(zip(axes.flat, test_samples)):\n",
    "    ax.imshow(img, cmap='viridis')\n",
    "    ax.set_title(f\"Sample {i}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Ground Truth Sinusoidal Patterns\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Reconstruction Test\n",
    "\n",
    "Test 1: Given a noisy version of a sinusoidal image, can the model reconstruct it?\n",
    "\n",
    "The model was trained only on visible regions, but must predict ALL pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def reconstruct_from_noise(model, num_samples=4):\n",
    "    \"\"\"Generate samples from pure noise.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Random noise\n",
    "    noise = torch.randn(num_samples, CHANNELS, RESOLUTION, RESOLUTION, device=DEVICE)\n",
    "    \n",
    "    # Get condition (dummy)\n",
    "    condition, uncondition = model.conditioner(noise)\n",
    "    \n",
    "    # Sample using EMA model\n",
    "    denoiser = model.ema_denoiser if model.ema_denoiser is not None else model.denoiser\n",
    "    \n",
    "    samples = model.diffusion_sampler(\n",
    "        denoiser,\n",
    "        noise,\n",
    "        condition,\n",
    "        uncondition,\n",
    "    )\n",
    "    \n",
    "    # Decode\n",
    "    images = model.vae.decode(samples)\n",
    "    \n",
    "    return images.clamp(0, 1).cpu().numpy()\n",
    "\n",
    "\n",
    "# Generate samples\n",
    "print(\"Generating samples from noise...\")\n",
    "generated = reconstruct_from_noise(model, num_samples=8)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i, (ax, img) in enumerate(zip(axes.flat, generated)):\n",
    "    ax.imshow(img[0], cmap='viridis')  # [C, H, W] -> [H, W]\n",
    "    ax.set_title(f\"Generated {i}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Generated Samples from Noise\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Interpolation Quality Analysis\n",
    "\n",
    "Key question: How well does the model predict UNSEEN regions?\n",
    "\n",
    "We compare:\n",
    "1. MSE on visible regions (training data)\n",
    "2. MSE on invisible regions (interpolation quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interpolation(ground_truth, generated, mask):\n",
    "    \"\"\"\n",
    "    Visualize interpolation quality.\n",
    "    \n",
    "    Shows:\n",
    "    - Ground truth\n",
    "    - Generated image\n",
    "    - Error map\n",
    "    - Visible/invisible region errors\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[0, 0].imshow(ground_truth, cmap='viridis')\n",
    "    axes[0, 0].set_title(\"Ground Truth\")\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Generated\n",
    "    axes[0, 1].imshow(generated, cmap='viridis')\n",
    "    axes[0, 1].set_title(\"Generated\")\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Error map\n",
    "    error = np.abs(ground_truth - generated)\n",
    "    im = axes[0, 2].imshow(error, cmap='hot', vmin=0, vmax=0.5)\n",
    "    axes[0, 2].set_title(\"Absolute Error\")\n",
    "    axes[0, 2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0, 2])\n",
    "    \n",
    "    # Visibility mask overlay\n",
    "    overlay = np.stack([ground_truth, ground_truth, ground_truth], axis=-1)\n",
    "    overlay[~mask] = [1, 0, 0]  # Red for invisible regions\n",
    "    axes[1, 0].imshow(overlay * 0.5 + 0.5 * ground_truth[..., np.newaxis])\n",
    "    axes[1, 0].set_title(\"Visibility Mask (red = unseen)\")\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Error on visible regions only\n",
    "    visible_error = error.copy()\n",
    "    visible_error[~mask] = 0\n",
    "    im = axes[1, 1].imshow(visible_error, cmap='hot', vmin=0, vmax=0.5)\n",
    "    visible_mse = (error[mask] ** 2).mean()\n",
    "    axes[1, 1].set_title(f\"Error on VISIBLE ({visible_mse:.4f} MSE)\")\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Error on invisible regions only\n",
    "    invisible_error = error.copy()\n",
    "    invisible_error[mask] = 0\n",
    "    im = axes[1, 2].imshow(invisible_error, cmap='hot', vmin=0, vmax=0.5)\n",
    "    invisible_mse = (error[~mask] ** 2).mean()\n",
    "    axes[1, 2].set_title(f\"Error on INVISIBLE ({invisible_mse:.4f} MSE)\")\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    ratio = invisible_mse / (visible_mse + 1e-8)\n",
    "    plt.suptitle(f\"Interpolation Quality - Ratio: {ratio:.2f}x (lower = better)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return visible_mse, invisible_mse, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze interpolation quality on generated samples\n",
    "# Note: Since we're generating from noise, we compare to generated pattern's smoothness\n",
    "\n",
    "# For a proper test, we would need to:\n",
    "# 1. Take a ground truth sinusoidal\n",
    "# 2. Add noise\n",
    "# 3. Denoise\n",
    "# 4. Compare to ground truth\n",
    "\n",
    "# Here we visualize the generated samples with the mask overlay\n",
    "for i in range(min(4, len(generated))):\n",
    "    gen_img = generated[i, 0]  # [H, W]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    # Generated image\n",
    "    axes[0].imshow(gen_img, cmap='viridis')\n",
    "    axes[0].set_title(\"Generated\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # With mask overlay\n",
    "    overlay = gen_img.copy()\n",
    "    axes[1].imshow(overlay, cmap='viridis')\n",
    "    # Draw mask boundaries\n",
    "    for start, end in VISIBLE_INTERVALS:\n",
    "        start_px = int(start * RESOLUTION)\n",
    "        end_px = int(end * RESOLUTION)\n",
    "        axes[1].axvline(x=start_px, color='r', linewidth=2, alpha=0.7)\n",
    "        axes[1].axvline(x=end_px, color='r', linewidth=2, alpha=0.7)\n",
    "    axes[1].set_title(\"Visible regions (between red lines)\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Gradient magnitude (smoothness check)\n",
    "    grad_x = np.abs(np.diff(gen_img, axis=1))\n",
    "    grad_y = np.abs(np.diff(gen_img, axis=0))\n",
    "    axes[2].imshow(grad_x[:-1, :], cmap='hot')\n",
    "    axes[2].set_title(\"Horizontal Gradient (edges)\")\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Sample {i} Analysis\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Boundary Analysis\n",
    "\n",
    "Check if there are visible artifacts at the boundaries between visible and invisible regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_boundaries(generated, mask):\n",
    "    \"\"\"\n",
    "    Analyze gradient magnitude at visibility boundaries.\n",
    "    \n",
    "    If interpolation is poor, we expect high gradients at boundaries.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for img in generated:\n",
    "        img = img[0]  # [H, W]\n",
    "        \n",
    "        # Compute gradient\n",
    "        grad_x = np.abs(np.diff(img, axis=1))\n",
    "        grad_x = np.pad(grad_x, ((0, 0), (0, 1)), mode='edge')\n",
    "        \n",
    "        # Find boundary pixels (where mask changes)\n",
    "        mask_diff = np.abs(np.diff(mask.astype(float), axis=1))\n",
    "        mask_diff = np.pad(mask_diff, ((0, 0), (0, 1)), mode='constant')\n",
    "        boundary_mask = mask_diff > 0\n",
    "        \n",
    "        # Gradient at boundaries vs elsewhere\n",
    "        grad_at_boundary = grad_x[boundary_mask].mean() if boundary_mask.any() else 0\n",
    "        grad_elsewhere = grad_x[~boundary_mask].mean()\n",
    "        \n",
    "        results.append({\n",
    "            'grad_at_boundary': grad_at_boundary,\n",
    "            'grad_elsewhere': grad_elsewhere,\n",
    "            'ratio': grad_at_boundary / (grad_elsewhere + 1e-8)\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Analyze boundaries\n",
    "boundary_results = analyze_boundaries(generated, visibility_mask)\n",
    "\n",
    "print(\"Boundary Analysis:\")\n",
    "print(\"(Ratio close to 1.0 = good interpolation, no boundary artifacts)\")\n",
    "print()\n",
    "for i, r in enumerate(boundary_results):\n",
    "    print(f\"Sample {i}: boundary_grad={r['grad_at_boundary']:.4f}, \"\n",
    "          f\"other_grad={r['grad_elsewhere']:.4f}, ratio={r['ratio']:.2f}\")\n",
    "\n",
    "avg_ratio = np.mean([r['ratio'] for r in boundary_results])\n",
    "print(f\"\\nAverage boundary ratio: {avg_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This benchmark tests neural field interpolation by:\n",
    "\n",
    "1. **Training** on only 20% of pixels (regular stripe pattern)\n",
    "2. **Evaluating** reconstruction quality on the unseen 80%\n",
    "3. **Checking** for boundary artifacts between seen/unseen regions\n",
    "\n",
    "### Key Metrics:\n",
    "- **Interpolation ratio** < 2.0: Good interpolation\n",
    "- **Boundary ratio** â‰ˆ 1.0: No boundary artifacts\n",
    "- **Visual smoothness**: Generated patterns should be smooth sinusoids\n",
    "\n",
    "### Next Steps:\n",
    "- Try different visibility ratios (10%, 30%, 50%)\n",
    "- Test grid mask (both rows and columns)\n",
    "- Compare different model architectures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
